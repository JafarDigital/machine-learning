{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf061003-c42d-4e42-8b42-81a489f9f85f",
   "metadata": {},
   "source": [
    "<b>A perceptron</b> is a type of artificial neuron used in machine learning for binary classification tasks. It processes input data by applying weights to the inputs, summing them, and using an activation function to produce an output, typically classifying the input into one of two categories.\n",
    "\n",
    "Here are manual implementation and implementation with scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a30b393-7201-48fe-9bfa-0ac0bcdf52af",
   "metadata": {},
   "source": [
    "<h3>Manual implementation using numpy</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc49879a-4f73-4fdc-8b8d-ee1619b4c07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "  Input: [0 0], Prediction: 0, Error: 0, Weights: [0. 0.], Bias: 0.0\n",
      "  Input: [0 1], Prediction: 0, Error: 1, Weights: [0.  0.1], Bias: 0.1\n",
      "  Input: [1 0], Prediction: 1, Error: 0, Weights: [0.  0.1], Bias: 0.1\n",
      "  Input: [1 1], Prediction: 1, Error: 0, Weights: [0.  0.1], Bias: 0.1\n",
      "Epoch 2\n",
      "  Input: [0 0], Prediction: 1, Error: -1, Weights: [0.  0.1], Bias: 0.0\n",
      "  Input: [0 1], Prediction: 1, Error: 0, Weights: [0.  0.1], Bias: 0.0\n",
      "  Input: [1 0], Prediction: 0, Error: 1, Weights: [0.1 0.1], Bias: 0.1\n",
      "  Input: [1 1], Prediction: 1, Error: 0, Weights: [0.1 0.1], Bias: 0.1\n",
      "Epoch 3\n",
      "  Input: [0 0], Prediction: 1, Error: -1, Weights: [0.1 0.1], Bias: 0.0\n",
      "  Input: [0 1], Prediction: 1, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "  Input: [1 0], Prediction: 1, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "  Input: [1 1], Prediction: 1, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "Epoch 4\n",
      "  Input: [0 0], Prediction: 0, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "  Input: [0 1], Prediction: 1, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "  Input: [1 0], Prediction: 1, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "  Input: [1 1], Prediction: 1, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "Epoch 5\n",
      "  Input: [0 0], Prediction: 0, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "  Input: [0 1], Prediction: 1, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "  Input: [1 0], Prediction: 1, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "  Input: [1 1], Prediction: 1, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "Epoch 6\n",
      "  Input: [0 0], Prediction: 0, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "  Input: [0 1], Prediction: 1, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "  Input: [1 0], Prediction: 1, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "  Input: [1 1], Prediction: 1, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "Epoch 7\n",
      "  Input: [0 0], Prediction: 0, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "  Input: [0 1], Prediction: 1, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "  Input: [1 0], Prediction: 1, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "  Input: [1 1], Prediction: 1, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "Epoch 8\n",
      "  Input: [0 0], Prediction: 0, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "  Input: [0 1], Prediction: 1, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "  Input: [1 0], Prediction: 1, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "  Input: [1 1], Prediction: 1, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "Epoch 9\n",
      "  Input: [0 0], Prediction: 0, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "  Input: [0 1], Prediction: 1, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "  Input: [1 0], Prediction: 1, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "  Input: [1 1], Prediction: 1, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "Epoch 10\n",
      "  Input: [0 0], Prediction: 0, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "  Input: [0 1], Prediction: 1, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "  Input: [1 0], Prediction: 1, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "  Input: [1 1], Prediction: 1, Error: 0, Weights: [0.1 0.1], Bias: 0.0\n",
      "\n",
      "Final weights: [0.1 0.1]\n",
      "Final bias: 0.0\n",
      "\n",
      "Testing:\n",
      "  Input: [0 0] → Predicted: 0, Expected: 0\n",
      "  Input: [0 1] → Predicted: 1, Expected: 1\n",
      "  Input: [1 0] → Predicted: 1, Expected: 1\n",
      "  Input: [1 1] → Predicted: 1, Expected: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def step(x):\n",
    "    return 1 if x > 0 else 0\n",
    "\n",
    "X = np.array([\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1]\n",
    "])\n",
    "\n",
    "y = np.array([0, 1, 1, 1])\n",
    "\n",
    "weights = np.zeros(X.shape[1])\n",
    "bias = 0\n",
    "lr = 0.1\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    for i in range(len(X)):\n",
    "        linear_output = np.dot(X[i], weights) + bias\n",
    "        prediction = step(linear_output)\n",
    "\n",
    "        error = y[i] - prediction\n",
    "\n",
    "        weights += lr * error * X[i]\n",
    "        bias += lr * error\n",
    "\n",
    "        print(f\"  Input: {X[i]}, Prediction: {prediction}, Error: {error}, Weights: {weights}, Bias: {bias}\")\n",
    "\n",
    "print(\"\\nFinal weights:\", weights)\n",
    "print(\"Final bias:\", bias)\n",
    "\n",
    "print(\"\\nTesting:\")\n",
    "for i in range(len(X)):\n",
    "    result = step(np.dot(X[i], weights) + bias)\n",
    "    print(f\"  Input: {X[i]} → Predicted: {result}, Expected: {y[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90826288-b483-4585-a05c-539061dbb243",
   "metadata": {},
   "source": [
    "<h3>Implementation using scikit-learn</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fe6dbbe-1574-47ab-b758-f2c24e6ab13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0 1 1 1]\n",
      "Confusion Matrix:\n",
      "[[1 0]\n",
      " [0 3]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "Weights: [[0.2 0.2]]\n",
      "Bias: [-0.1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "X = np.array([\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1]\n",
    "])\n",
    "\n",
    "y = np.array([0, 1, 1, 1])\n",
    "\n",
    "clf = Perceptron(max_iter=1000, eta0=0.1, random_state=42)\n",
    "clf.fit(X, y)\n",
    "\n",
    "y_pred = clf.predict(X)\n",
    "\n",
    "print(\"Predictions:\", y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y, y_pred))\n",
    "\n",
    "print(\"Weights:\", clf.coef_)\n",
    "print(\"Bias:\", clf.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a75db2-be3b-4caf-ad24-056b27624fc3",
   "metadata": {},
   "source": [
    "<h3>Multi-layer Perceptron (MLP)</h3>\n",
    "\n",
    "Multilayer perceptron (MLP) is a name for a modern feedforward neural network consisting of fully connected neurons with nonlinear activation functions, organized in layers, notable for being able to distinguish data that is not linearly separable. It is the basis of deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10ffd729-4953-4587-8161-6da6a29fc8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.6879\n",
      "Epoch 1000 Loss: 0.0188\n",
      "Epoch 2000 Loss: 0.0058\n",
      "Epoch 3000 Loss: 0.0032\n",
      "Epoch 4000 Loss: 0.0021\n",
      "Epoch 5000 Loss: 0.0016\n",
      "Epoch 6000 Loss: 0.0012\n",
      "Epoch 7000 Loss: 0.0010\n",
      "Epoch 8000 Loss: 0.0009\n",
      "Epoch 9000 Loss: 0.0007\n",
      "\n",
      "Predictions:\n",
      "Input: [0.0, 0.0], Predicted: 0, True: 0\n",
      "Input: [0.0, 1.0], Predicted: 1, True: 1\n",
      "Input: [1.0, 0.0], Predicted: 1, True: 1\n",
      "Input: [1.0, 1.0], Predicted: 0, True: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "X = torch.tensor([\n",
    "    [0., 0.],\n",
    "    [0., 1.],\n",
    "    [1., 0.],\n",
    "    [1., 1.]\n",
    "])\n",
    "\n",
    "y = torch.tensor([\n",
    "    [0.],\n",
    "    [1.],\n",
    "    [1.],\n",
    "    [0.]\n",
    "])\n",
    "\n",
    "class XOR_MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(2, 4)\n",
    "        self.out = nn.Linear(4, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.hidden(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "model = XOR_MLP()\n",
    "criterion = nn.BCEWithLogitsLoss() # Binary Cross Entropy + Sigmoid\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch {epoch} Loss: {loss.item():.4f}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(X)\n",
    "    predicted_labels = (predictions > 0.5).float()\n",
    "    print(\"\\nPredictions:\")\n",
    "    for i in range(4):\n",
    "        print(f\"Input: {X[i].tolist()}, Predicted: {int(predicted_labels[i].item())}, True: {int(y[i].item())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba71e67-23a4-4756-91d9-a86cb16a4c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
